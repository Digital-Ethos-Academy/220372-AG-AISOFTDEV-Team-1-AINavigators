{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Capstone Phase 2: AI-Powered Architecture & Data Design\n",
        "\n",
        "**Project:** StaffAlloc ‚Äì AI-Powered Project Staffing & Hours Allocation Tool\n",
        "\n",
        "**Objective:** Apply the Phase 2 guidance from the capstone README to transform the PRD into actionable architectural artifacts. We will prompt an LLM to propose a system architecture, generate PlantUML diagrams, capture key architectural decisions, and produce a normalized relational schema that aligns with the StaffAlloc vision.\n",
        "\n",
        "---\n",
        "\n",
        "## üìñ Overview\n",
        "\n",
        "Phase 2 concentrates on acting as the system architect. Following the README playbook, this notebook guides an AI co-pilot to:\n",
        "\n",
        "1. Synthesize the architecture from the PRD.\n",
        "2. Generate diagrams-as-code (PlantUML) artifacts.\n",
        "3. Capture architecture decision records (ADRs).\n",
        "4. Produce the relational database schema that will feed later phases.\n",
        "\n",
        "> All prompts use the authoritative context from `Artifacts/Documentation/prd.md`. Before running the notebook, verify your API credentials and project structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Before You Begin\n",
        "\n",
        "Make sure the following prerequisites are satisfied:\n",
        "\n",
        "1. `.env` file exists in the project root with a valid `GOOGLE_API_KEY` (see `SETUP.md`).\n",
        "2. Dependencies from `requirements.txt` are installed in your active environment.\n",
        "3. The Phase 1 artifacts‚Äîespecially `Artifacts/Documentation/prd.md`‚Äîare present.\n",
        "4. You have network access to call the selected LLM provider.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0: Install Required Packages\n",
        "\n",
        "Run this cell first to ensure the current kernel has the libraries needed for architecture generation, diagram rendering, and file management.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing required packages in the current kernel environment...\n",
            "Python executable: c:\\Users\\640109\\OneDrive - BOOZ ALLEN HAMILTON\\Documents\\AISE_Capstone\\220372-AG-AISOFTDEV-Team-1-AINavigators\\.venv\\Scripts\\python.exe\n",
            "Python version: 3.13.9 (tags/v3.13.9:8183fa5, Oct 14 2025, 14:09:13) [MSC v.1944 64 bit (AMD64)]\n",
            "======================================================================\n",
            "\n",
            "üì¶ Installing python-dotenv...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müì¶ Installing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-m\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstall\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-q\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   ‚úì \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m installed successfully\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess.CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\subprocess.py:414\u001b[39m, in \u001b[36mcheck_call\u001b[39m\u001b[34m(*popenargs, **kwargs)\u001b[39m\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_call\u001b[39m(*popenargs, **kwargs):\n\u001b[32m    405\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run command with arguments.  Wait for command to complete.  If\u001b[39;00m\n\u001b[32m    406\u001b[39m \u001b[33;03m    the exit code was zero then return, otherwise raise\u001b[39;00m\n\u001b[32m    407\u001b[39m \u001b[33;03m    CalledProcessError.  The CalledProcessError object will have the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    412\u001b[39m \u001b[33;03m    check_call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m     retcode = \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    415\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m retcode:\n\u001b[32m    416\u001b[39m         cmd = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33margs\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\subprocess.py:397\u001b[39m, in \u001b[36mcall\u001b[39m\u001b[34m(timeout, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m# Including KeyboardInterrupt, wait handled that.\u001b[39;00m\n\u001b[32m    399\u001b[39m         p.kill()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\subprocess.py:1280\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1278\u001b[39m     endtime = _time() + timeout\n\u001b[32m   1279\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1281\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[32m   1285\u001b[39m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\subprocess.py:1606\u001b[39m, in \u001b[36mPopen._wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1603\u001b[39m     timeout_millis = \u001b[38;5;28mint\u001b[39m(timeout * \u001b[32m1000\u001b[39m)\n\u001b[32m   1604\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.returncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1605\u001b[39m     \u001b[38;5;66;03m# API note: Returns immediately if timeout_millis == 0.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1606\u001b[39m     result = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWaitForSingleObject\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1607\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mtimeout_millis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1608\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result == _winapi.WAIT_TIMEOUT:\n\u001b[32m   1609\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m.args, timeout)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "print(\"Installing required packages in the current kernel environment...\")\n",
        "print(f\"Python executable: {sys.executable}\")\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "required_packages = [\n",
        "    \"python-dotenv\",\n",
        "    \"google-genai\",\n",
        "    \"plantuml\",\n",
        "    \"graphviz\",\n",
        "    \"pydantic\",\n",
        "]\n",
        "\n",
        "for package in required_packages:\n",
        "    print(f\"\\nüì¶ Installing {package}...\")\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "        print(f\"   ‚úì {package} installed successfully\")\n",
        "    except subprocess.CalledProcessError as exc:\n",
        "        print(f\"   ‚ùå Failed to install {package}: {exc}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"‚úÖ Package installation complete!\")\n",
        "print(\"\\nProceed to Step 1.\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Environment Setup\n",
        "\n",
        "This step mirrors the pattern from Phase 1. We will:\n",
        "\n",
        "1. Locate the project root and add it to the Python path.\n",
        "2. Load environment variables from `.env`.\n",
        "3. Import reusable helper utilities.\n",
        "4. Initialize the LLM client (default: `gemini-2.5-pro`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Locating project root and preparing environment...\n",
            "Project root: c:\\Users\\640109\\OneDrive - BOOZ ALLEN HAMILTON\\Documents\\AISE_Capstone\\220372-AG-AISOFTDEV-Team-1-AINavigators\n",
            "‚úì python-dotenv available\n",
            "‚úì Loaded environment variables from c:\\Users\\640109\\OneDrive - BOOZ ALLEN HAMILTON\\Documents\\AISE_Capstone\\220372-AG-AISOFTDEV-Team-1-AINavigators\\.env\n",
            "‚úì GOOGLE_API_KEY detected (AIzaSyBZ..._C7Q)\n",
            "‚úì Imported utilities from utils.py\n",
            "\n",
            "Initializing LLM client...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-05 10:29:23,997 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LLM ready (provider=google, model=gemini-2.5-pro)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "print(\"üìÅ Locating project root and preparing environment...\")\n",
        "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "print(f\"Project root: {project_root}\")\n",
        "\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    print(\"‚úì python-dotenv available\")\n",
        "except ImportError:\n",
        "    raise RuntimeError(\"python-dotenv is not installed. Run Step 0 first.\")\n",
        "\n",
        "env_path = os.path.join(project_root, \".env\")\n",
        "if os.path.exists(env_path):\n",
        "    load_dotenv(env_path)\n",
        "    print(f\"‚úì Loaded environment variables from {env_path}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è WARNING: .env file missing at {env_path}\")\n",
        "\n",
        "api_key_preview = os.getenv(\"GOOGLE_API_KEY\")\n",
        "if api_key_preview:\n",
        "    masked = f\"{api_key_preview[:8]}...{api_key_preview[-4:]}\" if len(api_key_preview) > 12 else \"***\"\n",
        "    print(f\"‚úì GOOGLE_API_KEY detected ({masked})\")\n",
        "else:\n",
        "    raise RuntimeError(\"GOOGLE_API_KEY not found. Add it to your .env file.\")\n",
        "\n",
        "try:\n",
        "    from utils import (\n",
        "        setup_llm_client,\n",
        "        get_completion,\n",
        "        clean_llm_output,\n",
        "        save_artifact,\n",
        "        load_artifact,\n",
        "    )\n",
        "    print(\"‚úì Imported utilities from utils.py\")\n",
        "except ImportError as err:\n",
        "    raise RuntimeError(f\"Unable to import project utilities: {err}\")\n",
        "\n",
        "print(\"\\nInitializing LLM client...\")\n",
        "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
        "print(f\"‚úÖ LLM ready (provider={api_provider}, model={model_name})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load Phase 1 Artifacts\n",
        "\n",
        "Fetch the authoritative PRD so we can embed it in subsequent prompts. The helper utilities persist artifacts under `Artifacts/`, matching the structure used in earlier labs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Loaded PRD from Artifacts/Documentation/prd.md\n",
            "Preview (first 600 characters):\n",
            "\n",
            "# Product Requirements Document: TripSplit - Group Travel Expense Manager\n",
            "\n",
            "## 1. Executive Summary & Vision\n",
            "\n",
            "**Product Name:** TripSplit\n",
            "\n",
            "**Overview:** TripSplit is a collaborative expense tracking application meticulously designed to simplify financial management for group travel. It empowers travelers to effortlessly create trips, add participants (even those without an account), log expenses with flexible splitting options, view real-time balances, and generate optimized settlement recommendations. By leveraging AI for smart categorization and a RAG-powered chat interface for quick insights\n"
          ]
        }
      ],
      "source": [
        "prd_path = \"Artifacts/Documentation/prd.md\"\n",
        "prd_content = load_artifact(prd_path)\n",
        "\n",
        "if prd_content:\n",
        "    print(f\"‚úì Loaded PRD from {prd_path}\")\n",
        "    print(\"Preview (first 600 characters):\\n\")\n",
        "    print(prd_content[:600])\n",
        "else:\n",
        "    raise FileNotFoundError(f\"PRD not found at {prd_path}. Confirm Phase 1 artifacts exist.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Architecture Challenges\n",
        "\n",
        "Following the README guidance, each challenge pairs a targeted prompt with automated artifact saving. For Phase 2 we align the architecture with the Day 3 FastAPI + SQLite labs so the full stack can run locally without paid cloud services.\n",
        "\n",
        "### Challenge 1 ‚Äì System Architecture Narrative\n",
        "\n",
        "**Goal:** Produce a comprehensive `architecture.md` document for a local-first prototype. Focus on:\n",
        "\n",
        "- High-level system overview sized for a single developer workstation\n",
        "- Responsibilities inside the FastAPI monolith, React client, and supporting utilities\n",
        "- Local integrations (SQLite, file-based storage, optional local vector database, SMTP dev server)\n",
        "- Data flow, privacy, and configuration management on a single machine\n",
        "- Evolution notes for scaling beyond the prototype\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Generating architecture narrative ---\n"
          ]
        }
      ],
      "source": [
        "architecture_prompt = f\"\"\"\n",
        "You are a senior solutions architect preparing a local-first prototype for the TripSplit platform. All runtime must execute on a single developer laptop without paid cloud dependencies. Align technology choices with the Day 3 FastAPI + SQLite labs (FastAPI, Pydantic, SQLAlchemy, SQLite, local file storage, optional local vector DB).\n",
        "\n",
        "## Product Context\n",
        "{prd_content}\n",
        "\n",
        "## Document Structure - Generate ALL sections below in a SINGLE, COMPLETE response:\n",
        "\n",
        "### 1. Executive Summary (2-3 paragraphs)\n",
        "- Overview of the local-first prototype approach\n",
        "- Key technology choices (FastAPI, SQLite, SQLAlchemy, local AI)\n",
        "- Goals and constraints\n",
        "\n",
        "### 2. Logical Architecture\n",
        "- **Client Layer**: React SPA, optional mobile client, CLI tools\n",
        "- **API Layer**: FastAPI routers organized by domain (users, trips, expenses, settlements, reports, ai)\n",
        "- **Service Layer**: Business logic, validation, orchestration\n",
        "- **Data Access Layer**: SQLAlchemy repositories, models\n",
        "- **Background Jobs**: APScheduler for async tasks\n",
        "- **Integration Adapters**: Local AI, vector store, file storage, SMTP\n",
        "\n",
        "### 3. Local Deployment Architecture\n",
        "- Process topology (uvicorn, React dev server, background worker)\n",
        "- Port assignments (8000 for API, 5173 for React, etc.)\n",
        "- Developer workflow (setup, run, test)\n",
        "- Directory structure\n",
        "\n",
        "### 4. Data & Storage Strategy\n",
        "- SQLite database with WAL mode\n",
        "- Alembic migrations\n",
        "- Local filesystem for receipts/reports\n",
        "- Optional Chroma/LanceDB for embeddings\n",
        "- Configuration via .env\n",
        "\n",
        "### 5. AI & Automation Features\n",
        "- Local LLM integration (Ollama/LM Studio)\n",
        "- Expense categorization pipeline\n",
        "- RAG chat implementation\n",
        "- Settlement optimization\n",
        "\n",
        "### 6. Security & Privacy\n",
        "- JWT authentication\n",
        "- Local secrets management\n",
        "- File permissions\n",
        "- Data encryption approach\n",
        "\n",
        "### 7. Testing & Quality\n",
        "- Pytest with in-memory SQLite\n",
        "- Integration test strategy\n",
        "- Linting (ruff, mypy)\n",
        "- CI/CD with GitHub Actions\n",
        "\n",
        "### 8. Observability\n",
        "- Logging (structlog)\n",
        "- Health check endpoints\n",
        "- Optional metrics/tracing\n",
        "\n",
        "### 9. Risks & Migration Path\n",
        "- Table format with risks, mitigations, and next steps\n",
        "- Evolution to cloud architecture\n",
        "\n",
        "CRITICAL: Generate the COMPLETE document with ALL sections above. Do not truncate or summarize. Provide full details for each section. The document should be 800-1200 lines of comprehensive Markdown.\n",
        "\n",
        "Respond in GitHub-flavored Markdown ready to save as `Artifacts/Documentation/architecture.md`.\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- Generating architecture narrative ---\")\n",
        "architecture_doc = get_completion(architecture_prompt, client, model_name, api_provider, temperature=0.3)\n",
        "print(architecture_doc[:800])\n",
        "\n",
        "save_artifact(architecture_doc, \"Artifacts/Documentation/architecture.md\")\n",
        "print(\"\\n‚úì Architecture document saved to Artifacts/Documentation/architecture.md\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 2 ‚Äì PlantUML System Diagram\n",
        "\n",
        "**Goal:** Capture the local system context as PlantUML diagrams-as-code. Request one diagram for the single-machine context and another for the FastAPI component breakdown so the visuals match the Day 3 lab stack (FastAPI, SQLite, files, local AI, MailHog). Save the PlantUML source for rendering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plantuml_prompt = f\"\"\"\n",
        "You are an enterprise architect creating diagrams-as-code. Using the TripSplit PRD and the updated local-first architecture narrative below, produce TWO COMPLETE PlantUML diagrams in a single response:\n",
        "\n",
        "## Diagram 1: System Context Diagram\n",
        "Show the complete local development environment:\n",
        "- Actors: Traveler, Trip Organizer\n",
        "- Developer Workstation boundary containing:\n",
        "  - React Web Client (localhost:5173)\n",
        "  - FastAPI Backend (localhost:8000)\n",
        "  - SQLite Database (file)\n",
        "  - Local File Storage (receipts, reports)\n",
        "  - Local Vector DB (Chroma/LanceDB)\n",
        "  - Local AI Runtime (Ollama/LM Studio)\n",
        "  - MailHog SMTP Server (localhost:8025)\n",
        "- Show all relationships and communication protocols\n",
        "\n",
        "## Diagram 2: Backend Component Diagram\n",
        "Break down the FastAPI application into:\n",
        "- API Routers (users, trips, expenses, settlements, reports, ai)\n",
        "- Service Layer (business logic)\n",
        "- Repository Layer (SQLAlchemy)\n",
        "- Domain Models (Pydantic + SQLAlchemy)\n",
        "- Background Jobs (APScheduler)\n",
        "- Adapters (AI, Vector Store, File Storage, SMTP)\n",
        "- External stores (SQLite, Filesystem, Chroma, Ollama, MailHog)\n",
        "- Show all dependencies and data flows\n",
        "\n",
        "## Product Context\n",
        "{prd_content}\n",
        "\n",
        "## Architecture Narrative\n",
        "{architecture_clean}\n",
        "\n",
        "CRITICAL REQUIREMENTS:\n",
        "- Generate BOTH complete diagrams with proper @startuml/@enduml blocks\n",
        "- Use C4-PlantUML notation (Person, System, Container, Component)\n",
        "- Include clear titles for each diagram\n",
        "- Show all relationships with descriptive labels\n",
        "- Add legends explaining colors/shapes if used\n",
        "- Output only PlantUML source code, no explanatory text\n",
        "\n",
        "Provide the complete PlantUML source for both diagrams now.\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- Generating PlantUML diagrams ---\")\n",
        "plantuml_source = get_completion(plantuml_prompt, client, model_name, api_provider, temperature=0.2)\n",
        "plantuml_clean = clean_llm_output(plantuml_source, language=\"plantuml\")\n",
        "print(plantuml_clean[:600])\n",
        "\n",
        "save_artifact(plantuml_clean, \"Artifacts/Architecture/tripsplit_system_diagrams.puml\")\n",
        "print(\"\\n‚úì PlantUML saved to Artifacts/Architecture/tripsplit_system_diagrams.puml\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 3 ‚Äì Architecture Decision Records (ADRs)\n",
        "\n",
        "**Goal:** Document critical architectural decisions for the local-first stack. Capture at least three ADRs that mirror the Day 3 lab choices: SQLite persistence, local AI/RAG strategy, and developer workstation runtime/tooling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "adr_prompt = f\"\"\"\n",
        "Act as an experienced software architect. Based on the TripSplit PRD and the local-first architecture narrative, author EXACTLY THREE comprehensive Architecture Decision Records (ADRs).\n",
        "\n",
        "## ADR Template - Use this structure for EACH ADR:\n",
        "\n",
        "### ADR-00X: [Clear Decision Title]\n",
        "\n",
        "**Status:** Accepted | Proposed | Deprecated\n",
        "**Date:** 2025-11-05\n",
        "**Context:** (2-3 paragraphs explaining the problem, constraints, and forces at play)\n",
        "**Decision:** (1-2 paragraphs stating what was decided and why)\n",
        "**Consequences:**\n",
        "- ‚úÖ Positive consequence 1\n",
        "- ‚úÖ Positive consequence 2\n",
        "- ‚úÖ Positive consequence 3\n",
        "- ‚ö†Ô∏è Negative consequence 1\n",
        "- ‚ö†Ô∏è Negative consequence 2\n",
        "**Alternatives Considered:** (Brief list of rejected options)\n",
        "**Follow-up Actions:** (Specific next steps or review criteria)\n",
        "\n",
        "## Required ADRs - Generate ALL THREE in full detail:\n",
        "\n",
        "### ADR-001: SQLite + SQLAlchemy for Local Persistence\n",
        "- Context: Need database for prototype, Day 3 labs use SQLite\n",
        "- Decision: Use SQLite with WAL mode, SQLAlchemy ORM, Alembic migrations\n",
        "- Consequences: Fast setup vs. limited concurrency\n",
        "- Alternatives: PostgreSQL, in-memory only\n",
        "- Follow-up: Migration path to PostgreSQL\n",
        "\n",
        "### ADR-002: Local AI/RAG with Open-Source Models\n",
        "- Context: Need AI categorization and chat without cloud costs\n",
        "- Decision: Ollama/LM Studio for LLM, Chroma for vector store\n",
        "- Consequences: Zero cost vs. lower quality/latency\n",
        "- Alternatives: OpenAI API, Google Gemini, no AI\n",
        "- Follow-up: Benchmark quality and create cloud migration plan\n",
        "\n",
        "### ADR-003: FastAPI Monolith with APScheduler\n",
        "- Context: Need async background jobs for local prototype\n",
        "- Decision: Single FastAPI process with APScheduler for jobs\n",
        "- Consequences: Simple setup vs. limited scalability\n",
        "- Alternatives: Celery+Redis, separate worker process\n",
        "- Follow-up: Define criteria for moving to distributed queue\n",
        "\n",
        "## Product Context\n",
        "{prd_content}\n",
        "\n",
        "## Architecture Narrative\n",
        "{architecture_clean}\n",
        "\n",
        "CRITICAL: Generate ALL THREE complete ADRs following the template above. Each ADR should be 15-25 lines. Total output should be 200-300 lines of comprehensive Markdown.\n",
        "\n",
        "Return complete ADRs in Markdown format suitable for `Artifacts/Documentation/adrs.md`.\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- Generating ADRs ---\")\n",
        "adrs_raw = get_completion(adr_prompt, client, model_name, api_provider, temperature=0.2)\n",
        "adrs_clean = clean_llm_output(adrs_raw, language=\"markdown\")\n",
        "print(adrs_clean[:600])\n",
        "\n",
        "save_artifact(adrs_clean, \"Artifacts/Documentation/adrs.md\")\n",
        "print(\"\\n‚úì ADRs saved to Artifacts/Documentation/adrs.md\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 4 ‚Äì Relational Schema Generation\n",
        "\n",
        "**Goal:** Translate the PRD and architecture outputs into a normalized relational database schema (SQLite-compatible) that we will consume in later labs. Include tables, relationships, indexes, and supporting constraints required for TripSplit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "schema_prompt = f\"\"\"\n",
        "You are a senior data architect. Using the TripSplit PRD and architecture narrative, produce a SQLite-compatible SQL schema. Requirements:\n",
        "\n",
        "- Use `CREATE TABLE` statements with appropriate data types, primary keys, foreign keys, and `ON DELETE` behaviors.\n",
        "- Include indexes, unique constraints, and check constraints that enforce the business rules.\n",
        "- Cover core entities: users, trips, participants, expenses, expense_splits, receipts, payments, AI artefacts (e.g., RAG cache), and audit metadata.\n",
        "- Add comments (`-- ...`) explaining non-obvious design choices.\n",
        "- Optimize for analytics by including summary/materialized view candidates or helper tables if helpful.\n",
        "- End the script with any seed data or helper views only if justified by the PRD.\n",
        "\n",
        "Respond with pure SQL ready to save into `artifacts/schema.sql`.\n",
        "\n",
        "## Product Context\n",
        "{prd_content}\n",
        "\n",
        "## Architecture Narrative\n",
        "{architecture_clean}\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- Generating SQL schema ---\")\n",
        "schema_sql = get_completion(schema_prompt, client, model_name, api_provider, temperature=0.1)\n",
        "schema_clean = clean_llm_output(schema_sql, language=\"sql\")\n",
        "print(schema_clean[:800])\n",
        "\n",
        "save_artifact(schema_clean, \"artifacts/schema.sql\")\n",
        "print(\"\\n‚úì Schema saved to artifacts/schema.sql\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 2 Wrap-Up\n",
        "\n",
        "You now have:\n",
        "\n",
        "- `Artifacts/Documentation/architecture.md` ‚Äì narrative architecture specification.\n",
        "- `Artifacts/Architecture/tripsplit_system_diagrams.puml` ‚Äì PlantUML diagrams for rendering with PlantUML/Graphviz.\n",
        "- `Artifacts/Documentation/adrs.md` ‚Äì curated architecture decision records.\n",
        "- `artifacts/schema.sql` ‚Äì normalized relational schema for TripSplit.\n",
        "\n",
        "These artifacts unlock Phase 3 (backend implementation). Continue the capstone by feeding the schema into the FastAPI generation workflows outlined in the Day 3 labs.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
